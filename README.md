# LSTM neural network for textual n-grams

Cognitive neuroscience is the study of how the human brain functions on tasks like decision making, language, perception and reasoning. Deep learning is a class of machine learning problems that use neural networks. They are designed to model the responses of neurons in the human brain. Learning can be supervised or unsupervised. N-gram token models are used extensively in language prediction. N-grams are probabilistic models that are used in predicting the next word or token. They are a statistical model of word sequences or tokens and are called Language Models or Lms. N-grams are essential in creating language prediction models. We are interested in exploring a broader eco-system enabling for Artificial Intelligence. Specifically, around Deep learning applications on unstructured content form on the web along the lines of the Google Brain project and Tensorflow.

